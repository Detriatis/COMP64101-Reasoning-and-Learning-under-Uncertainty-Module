 What is the binomial distribution used for?	 Modeling the number of successes in a fixed number of independent Bernoulli trials.	
 What is the categorical distribution used for?	 Modeling the probability of a variable taking on one of K different categories.	
 What is the Poisson distribution used for?	 Modeling the number of events occurring in a fixed interval of time if events occur at a constant rate and are independent.	
 What are the parameters of the Gamma distribution?	 a and b, where a is a shape parameter and b is a rate parameter. The Gamma distribution has support on R+.	
 What is the Beta distribution used for?	 Modeling a probability. The Beta distribution has support on the [0,1] interval.	
 What are the parameters of the Gaussian distribution?	 μ (mean) and σ² (variance).	
 What is the central limit theorem?	 The distribution of sample means from large samples tends towards a Gaussian distribution, regardless of the underlying distribution.	
" Why is the Gaussian distribution ""not robust""?"	 Sensitive to outliers due to exponentially fast decaying tails.	
 Give examples of more robust distributions.	 Laplace, Student t, Cauchy.	
 What are the parameters of the multivariate normal distribution?	 μ (mean vector) and Σ (covariance matrix).	
 What are different forms of the covariance matrix in the multivariate Gaussian?	 Full, Diagonal, and Spherical.	
 What is a mixture of Gaussian models (GMM)?	 A probability distribution constructed as a weighted sum of multiple Gaussian distributions.	
 What is a Matrix Normal distribution used for?	 Modeling matrix-valued random variables.	
 What is the Wishart distribution used for?	 Modeling covariance matrices.	
 What is the Dirichlet distribution used for?	 Modeling probability vectors (unit simplex).	
 Define conditional probability.	 P(A|B) = P(A ∩ B) / P(B)	
 How can the joint probability be rewritten using conditional probability?	 P(A ∩ B) = P(A|B)P(B) = P(B|A)P(A)	
 What does conditional probability measure?	 It measures how likely an event A is, given that event B has happened.	
 State the law of total probability.	 If {Aᵢ} forms a partition of Ω, then P(B) = ΣᵢP(B|Aᵢ)P(Aᵢ)	
 What does it mean for two events to be independent?	 P(A ∩ B) = P(A)P(B) or, equivalently, P(A|B) = P(A)	
 What does it mean for two events to be conditionally independent given a third event?	 P(A ∩ B | C) = P(A | C)P(B | C)	
 State Bayes' rule for events.	 P(E₁|E₂) = P(E₂|E₁)P(E₁) / P(E₂)	
 State Bayes' rule for the discrete case.	 p(X = k | E) = [p(E | X = k)p(X = k)] / [Σₖ'p(E | X = k')p(X = k')]	
 State Bayes' rule for the continuous case.	 p(x | E) = [p(E | x)p(x)] / [∫ₛ p(E | x')p(x')dx']	
 What is a Markov chain?	 A sequence of random variables where the probability of each future state depends only on the present state and not on past states.	
 State the Markov property.	 P(xt+τ | x₁, ..., xt) = P(xt+τ | xt)	
 What is a Markov model?	 A model based on the Markov property and can be described by the conditional probabilities of moving from one state to another.	
 What is a stationary Markov model?	 A Markov model where the probability of transitions does not depend on time.	
 What is a finite-state Markov chain?	 A Markov chain where the state space is finite.	
 What is a transition matrix?	 A matrix that represents the probabilities of transitioning between states in a Markov chain.	
 What is a stochastic matrix?	 A square matrix with non-negative entries such that the rows sum to 1.	
 What is an n-step transition matrix?	 A transition matrix that represents transition probabilities over n steps.	
 State the Chapman-Kolmogorov equation.	 Aij(m + n) = Σₖ Aᵢₖ(m)Aₖⱼ(n).	
 What does a Stationary distribution capture, and how is it denoted?	 The long-term distribution over states; denoted by π.	
 What is a probability space?	 A probability space is a triple (Ω, F, P) where  Ω is the sample space, F is the event space (a σ-algebra), and P is the probability measure.	
 What is the sample space (Ω)?	 The set of all possible outcomes of a random experiment.	
 What is the event space (F)?	 A collection of subsets of the sample space Ω; a σ-algebra.	
 What is a σ-algebra?	 A collection F of subsets of Ω that includes the empty set and Ω, is closed under complementation, and closed under countable unions and intersections.	
 What is the probability measure (P)?	 A function P  F → [0,1] that assigns a probability to each event in the event space F, and that satisfies the Kolmogorov axioms.	
 List the Kolmogorov axioms.	 (1) P(E) ≥ 0 for all E in F. (2) P(Ω) = 1. (3) For disjoint events, P(∪ᵢEᵢ) = ΣᵢP(Eᵢ).	
" What does ""only finite additivity"" imply about the Kolmogorov axioms?"	 The additivity axiom only holds for finite sets of disjoint events, rather than countable sets. (Subjectivist approach to probability de Finetti).	
 What is meant by super/subadditivity in probability?	 Relaxation of the standard additivity axiom; can represent imprecise probabilities where probabilities are given by intervals. (Imprecise Approach to Probability Walley (1991); Augustin et al. (2014)).	
 What is a random variable?	 A function that assigns a number to each outcome in the sample space.	
 What is a discrete random variable?	 A random variable whose range is countable.	
" What is the ""state space"" of a random variable?"	 The range of the random variable, i.e. the set of all possible values it can take.	
 What is a probability mass function (pmf)?	 A function that gives the probability of each discrete value of a random variable.	
 How do you represent a pmf?	 As a histogram or a parametric function.	
 What is a continuous random variable?	 A random variable that can take any value within a given range, i.e. non-countable.	
 What is the Lebesgue measure?	" A way to measure the length of intervals on the real line, and to quantify the ""size"" of sets, that is a generalization of the notion of length, area, and volume."	
 What is the Radon-Nikodym derivative?	 If probability P is absolutely continuous with respect to the Lebesgue measure (l), then the Radon-Nikodym derivative dP/dl exists, which is called the probability density function (pdf).	
 What is a probability density function (pdf)?	 A function, for a continuous random variable, whose integral over an interval is the probability of the variable falling in that interval.	
 What is a cumulative distribution function (cdf)?	 A function that gives the probability that a random variable is less than or equal to a given value.	
 How is the cdf defined for a continuous random variable?	 F(x) = P(X ≤ x) = ∫₋∞ˣ p(x')dx'	
 How does statistics differ from probability theory?	 Probability theory models outcomes given known parameters, statistics infers unknown parameters given observations.	
 What is Bayesian statistics?	 A framework for statistical inference that treats parameters as random variables and uses prior beliefs and observed data to compute posterior distributions.	
 What does the posterior distribution capture?	 The probability distribution of the parameters given observed data and prior beliefs.	
 What is a prior distribution?	 A probability distribution over parameters that represents our beliefs before observing the data.	
 What is the likelihood?	 The probability of the observed data given a specific parameter value.	
 What is the marginal likelihood?	 The probability of the observed data regardless of the value of parameters.	
 What is a Maximum A Posteriori (MAP) estimate?	 The parameter value that maximizes the posterior distribution.	
 How does MAP relate to Maximum Likelihood Estimation (MLE)?	 If a uniform prior is used in MAP, the MAP estimate becomes the MLE estimate.	
 When is the EM algorithm used, and what does it stand for?	 Expectation Maximization, used when probability models involve missing data/hidden variables to find MLE or MAP estimates.	
 What are Highest Density Regions (HDRs)?	 Parameter regions containing a specified percentage of the posterior probability mass with the narrowest interval for each percentage.	
 What is the posterior predictive distribution?	 The probability distribution of a new outcome given the observed data.	
 How does Bayesian inference avoid overfitting in ML problems?	 By integrating over the unknown parameters.	
 What is frequentist statistics?	 A framework for statistical inference that treats parameters as fixed and uses sampling distributions to quantify uncertainty.	
 What is an estimator in frequentist statistics?	 A decision procedure that specifies the action to take when given some observed data.	
 What is the sampling distribution?	 The distribution of an estimator if we repeat the experiment many times.	
 What is the parametric bootstrap?	 Approximating the sampling distribution using the estimated parameters to resample new datasets.	
 What does the asymptotic normality of the sampling distribution of the MLE state?	 The sampling distribution of the MLE converges to a Gaussian distribution with mean equal to the true parameter and precision equal to the Fisher Information matrix.	
 What are some drawbacks of Frequentist Statistics?	 Can have counter-intuitive properties; and struggles to represent prior knowledge.	
 What is a conjugate prior?	 A prior distribution where the posterior distribution is within the same family of distributions.	
 Why are conjugate priors used?	 To simplify the computation of the posterior.	
 What is a noninformative prior?	 A prior distribution that is designed to have a minimal effect on the posterior distribution.	
 What are hierarchical priors?	 Priors that have their own prior distributions (hyperparameters).	
 What is Empirical Bayes?	 An approach to setting the prior where the hyperparameters are first estimated using the data.	
 Define model selection.	 The process of selecting the best model from a set of different models.	
 Define model checking.	 Assessing the validity of a statistical model.	
